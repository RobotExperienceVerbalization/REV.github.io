<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Combining Episodic Memory and LLMs for the Verbalization of Robot Experiences</title>

    <meta name="author" content="Joana Plewnia">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="data/favicon.ico" type="image/x-icon">
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
<table class="main-table">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <p class="name" style="text-align: center;">
                Combining Episodic Memory and LLMs for the Verbalization of Robot Experiences
            </p>
            <div class="row">
                <div class="col-md-12 text-center">
                    <ul class="list-inline">
                        <br>
                        <li><a href="https://h2t.iar.kit.edu/21_2941.php">Joana Plewnia</a><sup>1</sup></li>
                        <li><a href="https://h2t.iar.kit.edu/21_2372.php">Tamim Asfour</a><sup>1</sup></li>
                        </li>
                    </ul>
                </div>
                <div class="text-center">
                    <a href="//kit.edu">
                        <img src="data/kit.svg" class="top-logo"></img>
                        <br/>
                        <sup>1</sup>Karlsruhe Institute of Technology, Germany
                    </a>
                    <br>
                    <br>
                </div>
            </div>
            <br/>
            <br/>
            <div class="row justify-content-md-center">
                <div class="col-md-2 text-center">
                    <a href="https://arxiv.org/abs/2409.17702">
                        <image src="data/paper_small.png" height="60px"></image>
                        <h4><strong>Paper</strong></h4>
                    </a>
                </div>
                <div class="col-md-2 text-center">
                    <a href="https://git.h2t.iar.kit.edu/sw/armarx/skills/verbalization">
                        <image src="data/github.png" height="60px"></image>
                        <h4><strong>Code</strong></h4>
                    </a>
                </div>
            </div>

            <hr/>

            <div class="row">
                <div class="col-md-12">
                    <h2>Abstract</h2>
                    <p>
                        The ability to communicate past experiences is fundamental for intelligent and natural interaction. Humanoid robots continuously accumulate rich, multi-modal experiential data and must be able to articulate their episodic experiences in natural language to support effective human-robot communication. Existing approaches either rely on the generalization capabilities of large language models (LLMs), sometimes combined with episodic memory, or the precision of rule-based verbalization systems, each presenting limitations when used in isolation. In this work, we present a novel hybrid framework that integrates the adaptability of LLMs with the robustness of rule-based methods and the generalizable structure of memory-based approaches.  
Our system implements strategies to retrieve and transform memory representations of past perceptions and actions into natural language responses. This enables humanoid robots to respond to natural language queries about their experience. Experimental evaluation based on a set of distinct query types demonstrates that our approach successfully answers 89.4\% of episodic memory questions with human-in-the-loop refinement, while reducing token consumption by 97\% compared to pure LLM-based methods. Furthermore, we demonstrate the system's extensibility by leveraging LLMs, such as GPT-4.1, to expand the range of permissible queries through example-based interaction. The evaluation on our humanoid robot \textit{(anonymized)} performing household tasks validates that our hybrid approach balances response quality with computational efficiency to address the crucial need for dependable yet flexible verbalization of robot experiences.  
                    </p>
                </div>
            </div>

            <div class="col-md-2 text-center">
                    <a href="https://git.h2t.iar.kit.edu/sw/armarx/skills/verbalization">
                        <image src="data/github.png" height="60px"></image>
                        <h4><strong>Code</strong></h4>
                    </a>
            </div>

            <hr/>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            This website is based on <a href="https://github.com/jonbarron/jonbarron_website">Jon
                            Barron's source code</a>.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>
</html>
