<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Combining Episodic Memory and LLMs for the Verbalization of Robot Experiences</title>

    <meta name="author" content="Joana Plewnia">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="data/favicon.ico" type="image/x-icon">
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
<table class="main-table">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <p class="name" style="text-align: center;">
                Combining Episodic Memory and LLMs for the Verbalization of Robot Experiences
            </p>
            <div class="row">
                <div class="col-md-12 text-center">
                    <ul class="list-inline">
                        <br>
                        <li><a href="https://h2t.iar.kit.edu/21_2941.php">Joana Plewnia</a><sup>1</sup></li>
                        <li><a href="https://h2t.iar.kit.edu/21_2372.php">Tamim Asfour</a><sup>1</sup></li>
                        </li>
                    </ul>
                </div>
                <div class="text-center">
                    <a href="//kit.edu">
                        <img src="images/kit_logo.png" class="top-logo"></img>
                        <br/>
                        <sup>1</sup>Karlsruhe Institute of Technology, Germany
                    </a>
                    <br>
                    <br>
                </div>
            </div>
            <br/>
            <br/>
            <div class="row justify-content-md-center">
                <div class="col-md-2 text-center">
                    <a href="https://arxiv.org/abs/2409.17702">
                        <image src="images/paper_small.png" height="60px"></image>
                        <h4><strong>Paper</strong></h4>
                    </a>
                </div>
                <div class="col-md-2 text-center">
                    <a href="https://git.h2t.iar.kit.edu/sw/armarx/skills/verbalization">
                        <image src="images/github.png" height="60px"></image>
                        <h4><strong>Code</strong></h4>
                    </a>
                </div>
            </div>

            <hr/>

            <div class="row">
                <div class="col-md-12">
                    <h2>Abstract</h2>
                     <br>
                    <p>
                        The ability to communicate past experiences is fundamental for intelligent and natural interaction. 
                        Humanoid robots continuously accumulate rich, multi-modal experiential data and must be able to articulate their episodic experiences in natural language to support effective human-robot communication. 
                        Existing approaches either rely on the generalization capabilities of large language models (LLMs), sometimes combined with episodic memory, or the precision of rule-based verbalization systems, 
                        each presenting limitations when used in isolation. In this work, we present a novel hybrid framework that integrates the adaptability of LLMs with the robustness of rule-based methods 
                        and the generalizable structure of memory-based approaches.  
                        Our system implements strategies to retrieve and transform memory representations of past perceptions and actions into natural language responses. 
                        This enables humanoid robots to respond to natural language queries about their experience. Experimental evaluation based on a set of distinct query types demonstrates that our 
                        approach successfully answers 89.4% of episodic memory questions with human-in-the-loop refinement, while reducing token consumption by 97% compared to pure LLM-based methods. 
                        Furthermore, we demonstrate the system's extensibility by leveraging LLMs, such as GPT-4.1, to expand the range of permissible queries through example-based interaction. 
                        The evaluation on our humanoid robot ARMAR-7 performing household tasks validates that our hybrid approach balances response quality with computational efficiency to address 
                        the crucial need for dependable yet flexible verbalization of robot experiences.  
                    </p>
                </div>
            </div>

            <hr/>

            <div class="col-md-12">
                <h2>Method Overview</h2>
                         <br>
                <div class="row">
                    <div class="col-sm-6 text-center">
                        <image src="images/MethodOverview.png" height="500px"></image>
                    </div>
                    <div class="col-sm-6 text-center">
                        <p>
                        The method comprises two main modules: the Question Answering (QA) module and the Question Generation (QG) module.
                        The QA module utilizes an existing question definition to extract parameters from the input question, leveraging the Question Template, followed by the sequential execution of the Select, Search, and Evaluate strategies. The outcome of the evaluation step is used to populate an Answer Template, resulting in a natural language response.
                        The QG module handles previously unseen questions by abstracting them into a Question Template for future matching. It then defines the corresponding Select, Search, and Evaluate strategies -- optionally leveraging a large language model (LLM) -- and generates a corresponding Answer Template.
                        </p>
                    </div>
                </div>     
            </div>

            <hr/>

            <div class="col-md-12 text-center">
                <h2>Results Overview</h2>
                 <br>
                        <image src="images/results_table.png" height="500px"></image>
                        
                        <p>
                            The evaluation revealed that automatically generated question definitions achieved a 53.12% success rate, which improved to 89.41% with human-in-the-loop adjustments. 
                            Simple question types (e.g., L.1, A.5) were accurately handled, while complex ones, especially involving multiple memory servers (C.1–C.3) or temporal reasoning (C.4), posed significant challenges. 
                            Minor manual interventions by expert users, like converting language expressions to internal identifiers, notably enhanced accuracy. 
                            Defining new question types took an average of 37.84 seconds, whereas answering based on pre-defined templates averaged 4.73 seconds and consumed only 326 tokens. 
                            Most processing effort occurred during the offline generation phase.
                            
                            In comparison, a pure LLM-based approach (per Bärmann et al.) achieved 5 fully and 2 partially correct answers out of 12 representative questions, 
                            where our approach generated 4 definitions fully correct on the first try and 5 definitions requiring only minor manual interventions for correct answers. 
                            The LLM-based approach consumed significantly more tokens (48,200/question) and showed higher latency (14.83 s/question). 
                            While the LLM excelled at core action-related queries, it struggled with peripheral or counting-related ones. 
                            Our method outperformed in these areas, avoided partially correct answers, and offered greater consistency and reliability once definitions were established. 
                            However, our system’s main limitation lies in the LLM’s ability to generate complex question definitions and its reliance on a rigid formalism that limits flexibility.
                        </p>
                </div>

            <hr/>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            This website is based on <a href="https://github.com/jonbarron/jonbarron_website">Jon
                            Barron's source code</a>.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>
</html>
